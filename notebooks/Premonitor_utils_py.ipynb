{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Premonitor: utils.py\n",
        "# This file contains helper functions used across the project, primarily for\n",
        "# data loading, pre-processing, and augmentation.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# Import our custom project configuration\n",
        "import config\n",
        "\n",
        "# --- Audio Processing Utilities ---\n",
        "\n",
        "def audio_to_spectrogram(audio_path):\n",
        "    \"\"\"\n",
        "    Loads a .wav file and converts it into a log-mel spectrogram.\n",
        "    This turns an audio signal into an image-like representation that a CNN can process.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=config.SPECTROGRAM_SAMPLE_RATE)\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(\n",
        "            y=y, sr=sr, n_mels=config.SPECTROGRAM_N_MELS, hop_length=config.SPECTROGRAM_HOP_LENGTH\n",
        "        )\n",
        "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "        return log_mel_spectrogram\n",
        "    except Exception as e:\n",
        "        if config.DEBUG_MODE:\n",
        "            print(f\"Error processing audio file {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_acoustic_dataset(data_dir, environmental_dirs=[]):\n",
        "    \"\"\"\n",
        "    Walks through dataset directories, loads audio files, converts them to spectrograms,\n",
        "    and creates training pairs.\n",
        "\n",
        "    For machine sounds (data_dir): Creates (normal_spec, 0) and (flipped_spec, 1) pairs.\n",
        "    For environmental sounds: Creates (env_spec, 2) pairs to be ignored.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Path to the primary machine sound dataset (e.g., MIMII).\n",
        "        environmental_dirs (list): List of paths to environmental sound datasets (e.g., Urbansound8K).\n",
        "\n",
        "    Returns:\n",
        "        A tuple (spectrograms, labels) ready for training.\n",
        "    \"\"\"\n",
        "    print(\"Creating acoustic dataset...\")\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "\n",
        "    # Process primary machine sounds for normal/anomaly training\n",
        "    normal_dir = os.path.join(data_dir, 'train', 'normal')\n",
        "    if not os.path.exists(normal_dir):\n",
        "        print(f\"Error: Directory not found - {normal_dir}\")\n",
        "    else:\n",
        "        normal_files = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith('.wav')]\n",
        "        for audio_file in tqdm(normal_files, desc=\"Processing normal machine audio\"):\n",
        "            spec = audio_to_spectrogram(audio_file)\n",
        "            if spec is not None:\n",
        "                spec_resized = tf.image.resize(spec[..., np.newaxis], config.ACOUSTIC_MODEL_INPUT_SHAPE[:2])\n",
        "                spectrograms.append(spec_resized)\n",
        "                labels.append(0) # Label 0 for 'normal'\n",
        "                spectrograms.append(tf.image.flip_up_down(spec_resized))\n",
        "                labels.append(1) # Label 1 for 'pseudo-anomaly'\n",
        "\n",
        "    # Process environmental sounds to be ignored\n",
        "    for env_dir in environmental_dirs:\n",
        "        if not os.path.exists(env_dir):\n",
        "            print(f\"Warning: Environmental sound directory not found - {env_dir}\")\n",
        "            continue\n",
        "        env_files = glob.glob(os.path.join(env_dir, '**', '*.wav'), recursive=True)\n",
        "        for audio_file in tqdm(env_files, desc=f\"Processing environmental audio from {os.path.basename(env_dir)}\"):\n",
        "            spec = audio_to_spectrogram(audio_file)\n",
        "            if spec is not None:\n",
        "                spec_resized = tf.image.resize(spec[..., np.newaxis], config.ACOUSTIC_MODEL_INPUT_SHAPE[:2])\n",
        "                spectrograms.append(spec_resized)\n",
        "                labels.append(2) # Label 2 for 'environmental/ignore'\n",
        "\n",
        "    # NOTE: For very large datasets, loading all data into a NumPy array can consume\n",
        "    # a lot of RAM. A more advanced approach would be to use tf.data.Dataset.from_generator.\n",
        "    # For the MVP, this approach is sufficient and simpler to debug.\n",
        "    return np.array(spectrograms), np.array(labels)\n",
        "\n",
        "\n",
        "# --- Image Processing Utilities ---\n",
        "\n",
        "def load_all_thermal_image_paths(dataset_dirs):\n",
        "    \"\"\"Scans multiple directories and returns a list of all image file paths.\"\"\"\n",
        "    all_paths = []\n",
        "    for data_dir in dataset_dirs:\n",
        "        if not os.path.exists(data_dir):\n",
        "            print(f\"Warning: Thermal dataset directory not found at '{data_dir}'. Skipping.\")\n",
        "            continue\n",
        "        # Use glob to find all image files recursively\n",
        "        image_files = glob.glob(os.path.join(data_dir, '**', '*.jpeg'), recursive=True)\n",
        "        image_files.extend(glob.glob(os.path.join(data_dir, '**', '*.jpg'), recursive=True))\n",
        "        image_files.extend(glob.glob(os.path.join(data_dir, '**', '*.png'), recursive=True))\n",
        "        all_paths.extend(image_files)\n",
        "    print(f\"Found a total of {len(all_paths)} thermal images for pre-training.\")\n",
        "    return all_paths\n",
        "\n",
        "def load_image_and_label(image_path, label):\n",
        "    \"\"\"Loads a single image and returns it with its label.\"\"\"\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, config.THERMAL_MODEL_INPUT_SHAPE[:2])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "def load_labeled_thermal_data(data_dir, batch_size, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    Loads a labeled dataset for fine-tuning, structured as:\n",
        "    - data_dir/normal/*.jpg\n",
        "    - data_dir/anomaly/*.jpg\n",
        "    \"\"\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Error: Labeled data directory not found at '{data_dir}'.\")\n",
        "        return None, None\n",
        "\n",
        "    # Create a tf.data.Dataset from the directory structure\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        labels='inferred',\n",
        "        label_mode='binary', # For normal vs anomaly\n",
        "        image_size=config.THERMAL_MODEL_INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        validation_split=validation_split,\n",
        "        subset='training',\n",
        "        seed=123\n",
        "    )\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        labels='inferred',\n",
        "        label_mode='binary',\n",
        "        image_size=config.THERMAL_MODEL_INPUT_SHAPE[:2],\n",
        "        batch_size=batch_size,\n",
        "        validation_split=validation_split,\n",
        "        subset='validation',\n",
        "        seed=123\n",
        "    )\n",
        "\n",
        "    # Normalize the images\n",
        "    normalization_layer = layers.Rescaling(1./255)\n",
        "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    return train_ds.prefetch(tf.data.AUTOTUNE), val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def augment_image(image):\n",
        "    \"\"\"Applies a set of random augmentations to an image for SimSiam training.\"\"\"\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_crop(image, size=[int(config.THERMAL_MODEL_INPUT_SHAPE[0]*0.8), int(config.THERMAL_MODEL_INPUT_SHAPE[1]*0.8), 3])\n",
        "    image = tf.image.resize(image, size=config.THERMAL_MODEL_INPUT_SHAPE[:2])\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image\n",
        "\n",
        "def create_thermal_dataset_generator(image_paths, batch_size):\n",
        "    \"\"\"Creates a memory-efficient TensorFlow data generator for the SimSiam model.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "\n",
        "    def load_for_siam(path):\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "        img = tf.image.resize(img, config.THERMAL_MODEL_INPUT_SHAPE[:2])\n",
        "        return tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    image_ds = path_ds.map(load_for_siam, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Create two augmented views for each image\n",
        "    view1_ds = image_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    view2_ds = image_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    paired_ds = tf.data.Dataset.zip((view1_ds, view2_ds))\n",
        "\n",
        "    return paired_ds.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9JLBBX3wWMzR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}