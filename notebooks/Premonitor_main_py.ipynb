{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Premonitor: main.py\n",
        "# This is the main entry point for the Premonitor application.\n",
        "# It runs a continuous loop to monitor the environment, processes data with\n",
        "# AI models, applies fusion logic, and triggers non-blocking alerts.\n",
        "# This script is intended to be run on the Raspberry Pi.\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Import our custom project files\n",
        "import config\n",
        "import alert_manager\n",
        "# For the MVP, we use the mock hardware. To switch to real hardware,\n",
        "# you would change this line to: import hardware_drivers as hardware\n",
        "import mock_hardware as hardware\n",
        "\n",
        "# --- Global variables for loaded AI models ---\n",
        "thermal_interpreter = None\n",
        "acoustic_interpreter = None\n",
        "# Add other models like LSTM AE here in the future.\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"\n",
        "    Loads the trained and quantized .tflite models into memory using the\n",
        "    TensorFlow Lite interpreter for high efficiency on the Pi.\n",
        "    \"\"\"\n",
        "    global thermal_interpreter, acoustic_interpreter\n",
        "    print(\"MAIN: Loading AI models...\")\n",
        "    try:\n",
        "        thermal_interpreter = tf.lite.Interpreter(model_path=config.THERMAL_MODEL_PATH)\n",
        "        thermal_interpreter.allocate_tensors()\n",
        "        print(f\"MAIN: Successfully loaded thermal model from {config.THERMAL_MODEL_PATH}\")\n",
        "\n",
        "        acoustic_interpreter = tf.lite.Interpreter(model_path=config.ACOUSTIC_MODEL_PATH)\n",
        "        acoustic_interpreter.allocate_tensors()\n",
        "        print(f\"MAIN: Successfully loaded acoustic model from {config.ACOUSTIC_MODEL_PATH}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"MAIN: CRITICAL ERROR - Failed to load one or more models: {e}\")\n",
        "        print(\"MAIN: The application cannot run without the AI models. Exiting.\")\n",
        "        exit()\n",
        "\n",
        "def run_inference(interpreter, input_data):\n",
        "    \"\"\"\n",
        "    A generic function to run inference on a loaded TFLite interpreter.\n",
        "    \"\"\"\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Prepare the input tensor (needs to be in a batch of 1)\n",
        "    input_tensor = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
        "\n",
        "    # Check if input shape matches model's expected shape\n",
        "    if not np.array_equal(input_details[0]['shape'][1:], input_data.shape):\n",
        "         print(f\"Error: Input data shape {input_data.shape} does not match model expected shape {input_details[0]['shape'][1:]}\")\n",
        "         return 0.0 # Return a non-anomaly score\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "    interpreter.invoke()\n",
        "    prediction = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "\n",
        "    # Assuming the model's output is a single value from a sigmoid function\n",
        "    return prediction[0]\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    The main function that orchestrates the Premonitor system.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Premonitor System ---\")\n",
        "\n",
        "    # --- Initialization ---\n",
        "    load_models()\n",
        "    hardware.initialize_mock_data() # Initialize our virtual sensors\n",
        "\n",
        "    # TODO: In a V2.0 product, load device-specific config from a JSON file.\n",
        "    # For now, we use the defaults from config.py.\n",
        "\n",
        "    # --- Main Monitoring Loop ---\n",
        "    print(\"\\n--- Starting main monitoring loop ---\")\n",
        "    while True:\n",
        "        try:\n",
        "            current_time = datetime.now().strftime('%H:%M:%S')\n",
        "            print(f\"\\n--- New check cycle at {current_time} ---\")\n",
        "\n",
        "            # 1. Read from sensors (using mock hardware for now)\n",
        "            thermal_image = hardware.read_thermal_image()\n",
        "            acoustic_spectrogram = hardware.read_acoustic_spectrogram()\n",
        "            gas_reading = hardware.read_gas_sensor()\n",
        "\n",
        "            # 2. Process data with AI models to get confidence scores\n",
        "            thermal_score = run_inference(thermal_interpreter, thermal_image)\n",
        "            acoustic_score = run_inference(acoustic_interpreter, acoustic_spectrogram)\n",
        "\n",
        "            if config.DEBUG_MODE:\n",
        "                print(f\"MAIN: Thermal Score={thermal_score:.2f}, Acoustic Score={acoustic_score:.2f}, Gas Reading={gas_reading}\")\n",
        "\n",
        "            # 3. Apply Sensor Fusion & Alerting Logic\n",
        "            # This is the core intelligence of the system.\n",
        "\n",
        "            # Case 1: High-confidence single-sensor alert (critical)\n",
        "            if thermal_score > config.THERMAL_ANOMALY_CONFIDENCE:\n",
        "                details = f\"A critical thermal anomaly was detected with a high confidence score of {thermal_score:.2f}.\"\n",
        "                alert_manager.send_alert_in_background(\"CRITICAL: High-Confidence Thermal Anomaly\", details)\n",
        "\n",
        "            elif acoustic_score > config.ACOUSTIC_ANOMALY_CONFIDENCE:\n",
        "                details = f\"A critical acoustic anomaly was detected with a high confidence score of {acoustic_score:.2f}.\"\n",
        "                alert_manager.send_alert_in_background(\"CRITICAL: High-Confidence Acoustic Anomaly\", details)\n",
        "\n",
        "            # Case 2: Correlated multi-sensor alert (proactive)\n",
        "            elif thermal_score > config.FUSION_CORRELATION_CONFIDENCE and acoustic_score > config.FUSION_CORRELATION_CONFIDENCE:\n",
        "                details = (f\"A potential issue was detected by correlating multiple weak signals.\\n\"\n",
        "                           f\"- Thermal anomaly score: {thermal_score:.2f} (Threshold: {config.FUSION_CORRELATION_CONFIDENCE})\\n\"\n",
        "                           f\"- Acoustic anomaly score: {acoustic_score:.2f} (Threshold: {config.FUSION_CORRELATION_CONFIDENCE})\")\n",
        "                alert_manager.send_alert_in_background(\"WARNING: Correlated Anomaly Detected\", details)\n",
        "\n",
        "            # Case 3: Simple threshold alert for basic sensors\n",
        "            if gas_reading > config.GAS_ANALOG_THRESHOLD:\n",
        "                details = f\"The gas sensor reading was {gas_reading}, which is above the threshold of {config.GAS_ANALOG_THRESHOLD}.\"\n",
        "                alert_manager.send_alert_in_background(\"WARNING: High Gas Level Detected\", details)\n",
        "\n",
        "            # 4. Wait for the next cycle\n",
        "            time.sleep(config.SENSOR_READ_INTERVAL)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n--- Shutdown signal received. Exiting Premonitor. ---\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"MAIN: An unhandled error occurred in the main loop: {e}\")\n",
        "            # In a real product, you might want to send a \"System Health\" alert here.\n",
        "            time.sleep(30) # Wait a bit before retrying to avoid spamming errors\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "22-fLNRZXPpt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}