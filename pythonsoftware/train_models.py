# -*- coding: utf-8 -*-
"""Premonitor_train_models_py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KDf8UhPuECMYUDg9pMonHlZMgKzhNOcH
"""

# Premonitor: train_models.py
# This script is responsible for training the core AI models for the Premonitor project.
# It should be run on a powerful development PC with a GPU.

import os
import argparse
import numpy as np
import tensorflow as tf
from tensorflow.keras import optimizers, losses, models, layers, callbacks

# Import our custom project files
import config
import model_blueprints
import utils # This will be created next
import dataset_loaders # Comprehensive dataset loading system

# --- Custom Loss Function for SimSiam Pre-training ---
def sim_siam_loss(p, z):
    """Calculates the negative cosine similarity loss for the SimSiam model."""
    z = tf.stop_gradient(z) # Crucial step to prevent model collapse
    p = tf.math.l2_normalize(p, axis=1)
    z = tf.math.l2_normalize(z, axis=1)
    return -tf.reduce_mean(tf.reduce_sum((p * z), axis=1))

# --- Main Training Functions ---

def train_thermal_model(epochs=50, batch_size=32, use_pretrained=True):
    """
    Orchestrates the full, two-stage training process for the thermal model.
    
    ARCHITECTURE:
    1. START with pretrained Xception weights (ImageNet - 14M images)
    2. Stage 1: Self-supervised pre-training on FLIR ADAS v2 (21,488 thermal images)
    3. Stage 2: Supervised fine-tuning on AAU VAP Trimodal (labeled anomalies)
    4. SAVE final weights → EXPORT to .tflite → DEPLOY to Raspberry Pi
    
    Args:
        epochs: Number of training epochs
        batch_size: Batch size for training
        use_pretrained: If True, starts with ImageNet pretrained weights (RECOMMENDED)
    """
    print("=" * 80)
    print(" " * 20 + "THERMAL MODEL TRAINING PIPELINE")
    print("=" * 80)
    print(f"Using Pretrained Weights: {'YES (Xception/ImageNet)' if use_pretrained else 'NO (from scratch)'}")
    print("=" * 80)

    # --- STAGE 1: SELF-SUPERVISED PRE-TRAINING ON FLIR ---
    print("\n--- STAGE 1: Self-Supervised Pre-training on FLIR ADAS v2 ---")
    print("Goal: Adapt ImageNet features to thermal imaging domain")

    # 1. Load FLIR thermal images for pre-training (21,488 unlabeled images)
    flir_loader = dataset_loaders.FLIRDatasetLoader()
    unlabeled_image_paths = flir_loader.load_thermal_images_for_pretraining(include_val=True)
    train_dataset = utils.create_thermal_dataset_generator(unlabeled_image_paths, batch_size)

    # 2. Get Model Blueprints with Pretrained Weights
    # NOTE: model_blueprints.get_thermal_anomaly_model() already uses weights='imagenet'
    # This initializes the Xception backbone with ImageNet pretrained weights
    siamese_model, encoder, _ = model_blueprints.get_thermal_anomaly_model()
    
    if use_pretrained:
        print("✓ Loaded Xception backbone with ImageNet pretrained weights")
        print("  This gives us features learned from 14M images!")
    else:
        print("⚠ Training from scratch (not recommended - takes much longer)")
    
    siamese_model.compile(optimizer=optimizers.Adam(0.001))

    # 3. Custom Training Loop for SimSiam
    print(f"Starting SimSiam pre-training for {epochs} epochs...")
    for epoch in range(epochs):
        total_loss = 0
        for step, (view1, view2) in enumerate(train_dataset):
            with tf.GradientTape() as tape:
                p_a, z_a, p_b, z_b = siamese_model([view1, view2], training=True)
                loss = (sim_siam_loss(p_a, z_b) + sim_siam_loss(p_b, z_a)) / 2

            gradients = tape.gradient(loss, siamese_model.trainable_variables)
            siamese_model.optimizer.apply_gradients(zip(gradients, siamese_model.trainable_variables))
            total_loss += loss

        avg_loss = total_loss / (step + 1)
        print(f"Epoch {epoch+1}/{epochs}, Pre-training Loss: {avg_loss:.4f}")

    # 4. Save the Pre-trained Encoder
    # This encoder now has:
    #   - ImageNet features (edges, textures, objects) from 14M images
    #   - Thermal-specific features from 21,488 FLIR images
    encoder_save_path = os.path.join(config.MODEL_DIR, "thermal_encoder_pretrained.h5")
    if not os.path.exists(config.MODEL_DIR): os.makedirs(config.MODEL_DIR)
    encoder.save(encoder_save_path)
    print(f"\n✓ Pre-trained encoder saved to {encoder_save_path}")
    print(f"  This encoder combines ImageNet + FLIR knowledge!")

    # --- STAGE 2: SUPERVISED FINE-TUNING ON AAU VAP ---
    print("\n" + "=" * 80)
    print("--- STAGE 2: Supervised Fine-tuning on AAU VAP Trimodal ---")
    print("Goal: Learn to detect specific anomalies (people, hotspots, fire)")
    print("=" * 80)

    # 1. Load AAU VAP labeled thermal data (14,000+ images with annotations)
    aau_loader = dataset_loaders.AAUVAPTrimodalDatasetLoader()
    image_paths, labels = aau_loader.load_thermal_images_with_labels(scenes_to_use=['Scene 1', 'Scene 2'])
    
    # Convert to TensorFlow dataset
    # Split 80% train, 20% validation
    split_idx = int(0.8 * len(image_paths))
    train_paths, val_paths = image_paths[:split_idx], image_paths[split_idx:]
    train_labels, val_labels = labels[:split_idx], labels[split_idx:]
    
    def load_and_preprocess(path, label):
        img = tf.io.read_file(path)
        img = tf.image.decode_png(img, channels=3)
        img = tf.image.resize(img, config.THERMAL_MODEL_INPUT_SHAPE[:2])
        img = tf.cast(img, tf.float32) / 255.0
        return img, tf.cast(label, tf.float32)
    
    labeled_train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))
    labeled_train_ds = labeled_train_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    labeled_train_ds = labeled_train_ds.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)
    
    labeled_val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))
    labeled_val_ds = labeled_val_ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    labeled_val_ds = labeled_val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)

    # 2. Build the Classifier Model
    # Load the pre-trained encoder and freeze its backbone layers.
    pretrained_encoder = models.load_model(encoder_save_path)
    pretrained_encoder.trainable = False # Start with the backbone frozen

    # Add a new classification head
    classifier_input = layers.Input(shape=config.THERMAL_MODEL_INPUT_SHAPE)
    x = pretrained_encoder(classifier_input, training=False)
    # Add a dropout layer for regularization to prevent overfitting
    x = layers.Dropout(0.5)(x)
    # The final output layer for binary classification (normal vs anomaly)
    classifier_output = layers.Dense(1, activation='sigmoid')(x)
    classifier_model = models.Model(classifier_input, classifier_output, name="thermal_classifier")

    # 3. Compile and Train the Classifier
    classifier_model.compile(
        optimizer=optimizers.Adam(learning_rate=0.0001), # Use a smaller learning rate for fine-tuning
        loss=losses.BinaryCrossentropy(),
        metrics=['accuracy']
    )

    # 4. Add Checkpointing to Save the Best Model
    # This saves the model only when validation accuracy improves.
    checkpoint_path = os.path.join(config.MODEL_DIR, "thermal_classifier_best.h5")
    model_checkpoint_callback = callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        save_weights_only=False,
        monitor='val_accuracy',
        mode='max',
        save_best_only=True)

    print(f"Starting classifier fine-tuning for {epochs // 2} epochs...")
    classifier_model.fit(
        labeled_train_ds,
        epochs=epochs // 2, # Fine-tuning usually requires fewer epochs
        validation_data=labeled_val_ds,
        callbacks=[model_checkpoint_callback]
    )

    print(f"\n{'=' * 80}")
    print(f"✓ THERMAL MODEL TRAINING COMPLETE!")
    print(f"{'=' * 80}")
    print(f"Final model saved to: {checkpoint_path}")
    print(f"This model contains:")
    print(f"  1. ImageNet pretrained features (14M images)")
    print(f"  2. FLIR thermal domain knowledge (21,488 images)")
    print(f"  3. AAU VAP anomaly detection (14,000+ labeled images)")
    print(f"\nNext step: Export to .tflite for Raspberry Pi deployment")
    print(f"  Command: python export_tflite.py --model thermal --quantize int8")
    print(f"{'=' * 80}\n")

def train_acoustic_model(epochs=30, batch_size=64, use_pretrained=True):
    """
    Orchestrates the training for the acoustic anomaly model.
    
    ARCHITECTURE:
    1. START with pretrained audio features (AudioSet - 2M YouTube clips) [FUTURE]
    2. Train on MIMII (1,418+ labeled machine sounds)
    3. Add ESC-50 environmental sounds for robustness
    4. SAVE final weights → EXPORT to .tflite → DEPLOY to Raspberry Pi
    
    Args:
        epochs: Number of training epochs
        batch_size: Batch size for training
        use_pretrained: If True, use pretrained audio features (TODO: integrate YAMNet)
    """
    print("=" * 80)
    print(" " * 20 + "ACOUSTIC MODEL TRAINING PIPELINE")
    print("=" * 80)
    
    if use_pretrained:
        print("⚠ Pretrained audio weights (YAMNet) not yet integrated")
        print("  For V2.0: Will use AudioSet pretrained features")
        print("  Current: Training from scratch with MIMII + ESC-50")
    else:
        print("Training from scratch (current implementation)")
    print("=" * 80)

    # 1. Load MIMII dataset (industrial fan sounds - perfect for lab equipment!)
    print("\n### Loading Primary Dataset: MIMII ###")
    mimii_loader = dataset_loaders.MIMIIDatasetLoader()
    spectrograms, labels = mimii_loader.load_all_machine_sounds(use_all_ids=True)
    
    # Optional: Add environmental sounds as negative examples
    print("\n### Loading Environmental Sounds for Robustness ###")
    try:
        esc50_loader = dataset_loaders.ESC50DatasetLoader()
        env_specs, env_labels = esc50_loader.load_environmental_sounds(fire_classes_only=False)
        
        # Combine datasets: MIMII (0=normal, 1=abnormal) + ESC-50 (2=environmental)
        spectrograms = np.concatenate([spectrograms, env_specs], axis=0)
        labels = np.concatenate([labels, np.full(len(env_labels), 2)], axis=0)  # Label 2 = ignore
        print(f"✓ Combined dataset size: {len(spectrograms)} samples")
    except Exception as e:
        print(f"⚠ Skipping environmental sounds: {e}")

    # 2. Get Model Blueprint
    # TODO V2.0: Integrate YAMNet pretrained weights from fetch_pretrained_weights.py
    acoustic_model = model_blueprints.get_acoustic_anomaly_model()

    # 3. Compile the Model
    acoustic_model.compile(
        optimizer=optimizers.Adam(learning_rate=0.001),
        loss=losses.BinaryCrossentropy(),
        metrics=['accuracy']
    )

    # 4. Add Checkpointing
    checkpoint_path = os.path.join(config.MODEL_DIR, "acoustic_anomaly_model_best.h5")
    model_checkpoint_callback = callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        save_weights_only=False,
        monitor='val_accuracy',
        mode='max',
        save_best_only=True)

    # 5. Training
    print(f"\nStarting acoustic model training for {epochs} epochs...")
    acoustic_model.fit(
        spectrograms,
        labels,
        epochs=epochs,
        batch_size=batch_size,
        validation_split=0.2,
        callbacks=[model_checkpoint_callback]
    )
    
    print(f"\n{'=' * 80}")
    print(f"✓ ACOUSTIC MODEL TRAINING COMPLETE!")
    print(f"{'=' * 80}")
    print(f"Final model saved to: {checkpoint_path}")
    print(f"This model learned from:")
    print(f"  1. MIMII industrial fan sounds (1,418+ normal/abnormal)")
    print(f"  2. ESC-50 environmental sounds (2,000 diverse sounds)")
    print(f"  → Total training samples: {len(spectrograms)}")
    print(f"\nNext step: Export to .tflite for Raspberry Pi deployment")
    print(f"  Command: python export_tflite.py --model acoustic --quantize int8")
    print(f"{'=' * 80}\n")

def train_lstm_autoencoder(epochs=50, batch_size=32, sequence_length=50):
    """
    Orchestrates the training for the LSTM Autoencoder model for time-series anomaly detection.
    
    ARCHITECTURE:
    1. Load Turbofan engine degradation data (sensor time-series)
    2. Train LSTM Autoencoder to learn normal operating patterns
    3. Detect anomalies as high reconstruction error
    4. SAVE final weights → EXPORT to .tflite → DEPLOY to Raspberry Pi
    
    USE CASE: Predict fridge compressor failure by monitoring vibration/temperature trends
    
    Args:
        epochs: Number of training epochs
        batch_size: Batch size for training
        sequence_length: Number of timesteps in each sequence window
    """
    print("=" * 80)
    print(" " * 20 + "LSTM AUTOENCODER TRAINING PIPELINE")
    print("=" * 80)
    print("Use Case: Predictive maintenance for lab equipment")
    print("Method: Learn normal patterns, flag deviations as anomalies")
    print("=" * 80)

    # 1. Load Turbofan dataset (equipment degradation time-series)
    print("\n### Loading Turbofan Engine Degradation Dataset ###")
    turbofan_loader = dataset_loaders.TurbofanDatasetLoader()
    X_train, X_test, y_rul = turbofan_loader.load_turbofan_data(dataset_id='FD001')
    
    if X_train is None:
        print("\n❌ ERROR: Turbofan dataset not found or not extracted!")
        print("Please extract the dataset first:")
        print("  cd 'd:/PREMONITOR/datasets/time-series anomaly detection datasets'")
        print("  Expand-Archive '17.+Turbofan+Engine+Degradation+Simulation+Data+Set+2.zip' -DestinationPath '.'")
        return
    
    print(f"✓ Loaded training data: {X_train.shape}")
    print(f"✓ Loaded test data: {X_test.shape}")
    print(f"  21 sensor readings per timestep (temp, pressure, vibration, etc.)")
    
    # 2. Normalize data (critical for LSTM training)
    print("\n### Normalizing sensor data ###")
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 3. Create sequences (sliding window)
    print(f"\n### Creating sequences (window size: {sequence_length}) ###")
    def create_sequences(data, seq_length):
        sequences = []
        for i in range(len(data) - seq_length + 1):
            sequences.append(data[i:i+seq_length])
        return np.array(sequences)
    
    X_train_seq = create_sequences(X_train_scaled, sequence_length)
    X_test_seq = create_sequences(X_test_scaled, sequence_length)
    
    print(f"✓ Training sequences: {X_train_seq.shape}")
    print(f"✓ Test sequences: {X_test_seq.shape}")
    
    # 4. Get LSTM Autoencoder model
    n_features = X_train.shape[1]  # 21 sensor features
    lstm_model = model_blueprints.get_lstm_autoencoder_model(
        timesteps=sequence_length, 
        n_features=n_features
    )
    
    # 5. Compile model
    lstm_model.compile(
        optimizer=optimizers.Adam(learning_rate=0.001),
        loss=losses.MeanSquaredError(),
        metrics=['mae']
    )
    
    print(f"\n### Model Summary ###")
    lstm_model.summary()
    
    # 6. Add callbacks
    checkpoint_path = os.path.join(config.MODEL_DIR, "lstm_autoencoder_best.h5")
    early_stopping = callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True
    )
    model_checkpoint = callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        save_weights_only=False,
        monitor='val_loss',
        mode='min',
        save_best_only=True
    )
    
    # 7. Train the autoencoder (unsupervised - learns to reconstruct normal data)
    print(f"\n### Training LSTM Autoencoder for {epochs} epochs ###")
    print("Goal: Learn to reconstruct normal equipment operation")
    
    history = lstm_model.fit(
        X_train_seq, X_train_seq,  # Autoencoder: input = output
        epochs=epochs,
        batch_size=batch_size,
        validation_split=0.2,
        callbacks=[early_stopping, model_checkpoint],
        verbose=1
    )
    
    # 8. Evaluate on test data
    print("\n### Evaluating on test data ###")
    test_reconstructions = lstm_model.predict(X_test_seq)
    reconstruction_errors = np.mean(np.square(X_test_seq - test_reconstructions), axis=(1, 2))
    
    # Calculate threshold (95th percentile of training errors)
    train_reconstructions = lstm_model.predict(X_train_seq[:1000])  # Sample for efficiency
    train_errors = np.mean(np.square(X_train_seq[:1000] - train_reconstructions), axis=(1, 2))
    threshold = np.percentile(train_errors, 95)
    
    print(f"✓ Reconstruction error threshold: {threshold:.6f}")
    print(f"✓ Anomalies detected in test set: {np.sum(reconstruction_errors > threshold)}/{len(reconstruction_errors)}")
    
    # 9. Save threshold for deployment
    threshold_file = os.path.join(config.MODEL_DIR, "lstm_threshold.txt")
    with open(threshold_file, 'w') as f:
        f.write(str(threshold))
    print(f"✓ Threshold saved to: {threshold_file}")
    
    print(f"\n{'=' * 80}")
    print(f"✓ LSTM AUTOENCODER TRAINING COMPLETE!")
    print(f"{'=' * 80}")
    print(f"Final model saved to: {checkpoint_path}")
    print(f"Anomaly threshold: {threshold:.6f}")
    print(f"\nThis model learned from:")
    print(f"  1. Turbofan engine degradation patterns (multiple units)")
    print(f"  2. 21 sensor readings (temperature, pressure, vibration, etc.)")
    print(f"  3. Time-series sequences of length {sequence_length}")
    print(f"\nDEPLOYMENT USE CASE:")
    print(f"  → Monitor fridge compressor sensor readings over time")
    print(f"  → Detect degradation patterns similar to Turbofan failures")
    print(f"  → Predict failure BEFORE catastrophic breakdown")
    print(f"  → Alert: 'Fridge showing degradation pattern (RUL: ~7 days)'")
    print(f"\nNext step: Export to .tflite for Raspberry Pi deployment")
    print(f"  Command: python export_tflite.py --model lstm --quantize int8")
    print(f"{'=' * 80}\n")

# --- Command-Line Interface ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Premonitor AI Model Training Script")
    parser.add_argument(
        "--model", type=str, required=True, choices=["thermal", "acoustic", "lstm"],
        help="The type of model to train ('thermal', 'acoustic', or 'lstm')."
    )
    args = parser.parse_args()

    # Create model directory if it doesn't exist
    if not os.path.exists(config.MODEL_DIR):
        os.makedirs(config.MODEL_DIR)

    if args.model == "thermal":
        print("=" * 70)
        print(" " * 15 + "THERMAL MODEL TRAINING")
        print("  Pre-training: FLIR ADAS v2 (21,488 images)")
        print("  Fine-tuning: AAU VAP Trimodal (14,000+ labeled images)")
        print("=" * 70)
        train_thermal_model(epochs=50, batch_size=32)
    elif args.model == "acoustic":
        print("=" * 70)
        print(" " * 15 + "ACOUSTIC MODEL TRAINING")
        print("  Primary: MIMII (1,418+ normal/abnormal fan sounds)")
        print("  Auxiliary: ESC-50 + UrbanSound8K (environmental sounds)")
        print("=" * 70)
        train_acoustic_model(epochs=30, batch_size=64)
    elif args.model == "lstm":
        print("=" * 70)
        print(" " * 15 + "LSTM AUTOENCODER TRAINING")
        print("  Dataset: Turbofan Engine Degradation (time-series)")
        print("  Use Case: Predict fridge failure via sensor trends")
        print("=" * 70)
        train_lstm_autoencoder(epochs=50, batch_size=32, sequence_length=50)
    else:
        print("Invalid model type specified.")